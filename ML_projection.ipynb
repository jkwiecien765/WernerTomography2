{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from myPackage.my_module import *\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10000 done\n",
      "20/10000 done\n",
      "30/10000 done\n",
      "40/10000 done\n",
      "50/10000 done\n",
      "60/10000 done\n",
      "70/10000 done\n",
      "80/10000 done\n",
      "90/10000 done\n",
      "100/10000 done\n",
      "110/10000 done\n",
      "120/10000 done\n",
      "130/10000 done\n",
      "140/10000 done\n",
      "150/10000 done\n",
      "160/10000 done\n",
      "170/10000 done\n",
      "180/10000 done\n",
      "190/10000 done\n",
      "200/10000 done\n",
      "210/10000 done\n",
      "220/10000 done\n",
      "230/10000 done\n",
      "240/10000 done\n",
      "250/10000 done\n",
      "260/10000 done\n",
      "270/10000 done\n",
      "280/10000 done\n",
      "290/10000 done\n",
      "300/10000 done\n",
      "310/10000 done\n",
      "320/10000 done\n",
      "330/10000 done\n",
      "340/10000 done\n",
      "350/10000 done\n",
      "360/10000 done\n",
      "370/10000 done\n",
      "380/10000 done\n",
      "390/10000 done\n",
      "400/10000 done\n",
      "410/10000 done\n",
      "420/10000 done\n",
      "430/10000 done\n",
      "440/10000 done\n",
      "450/10000 done\n",
      "460/10000 done\n",
      "470/10000 done\n",
      "480/10000 done\n",
      "490/10000 done\n",
      "500/10000 done\n",
      "510/10000 done\n",
      "520/10000 done\n",
      "530/10000 done\n",
      "540/10000 done\n",
      "550/10000 done\n",
      "560/10000 done\n",
      "570/10000 done\n",
      "580/10000 done\n",
      "590/10000 done\n",
      "600/10000 done\n",
      "610/10000 done\n",
      "620/10000 done\n",
      "630/10000 done\n",
      "640/10000 done\n",
      "650/10000 done\n",
      "660/10000 done\n",
      "670/10000 done\n",
      "680/10000 done\n",
      "690/10000 done\n",
      "700/10000 done\n",
      "710/10000 done\n",
      "720/10000 done\n",
      "730/10000 done\n",
      "740/10000 done\n",
      "750/10000 done\n",
      "760/10000 done\n",
      "770/10000 done\n",
      "780/10000 done\n",
      "790/10000 done\n",
      "800/10000 done\n",
      "810/10000 done\n",
      "820/10000 done\n",
      "830/10000 done\n",
      "840/10000 done\n",
      "850/10000 done\n",
      "860/10000 done\n",
      "870/10000 done\n",
      "880/10000 done\n",
      "890/10000 done\n",
      "900/10000 done\n",
      "910/10000 done\n",
      "920/10000 done\n",
      "930/10000 done\n",
      "940/10000 done\n",
      "950/10000 done\n",
      "960/10000 done\n",
      "970/10000 done\n",
      "980/10000 done\n",
      "990/10000 done\n",
      "1000/10000 done\n",
      "1010/10000 done\n",
      "1020/10000 done\n",
      "1030/10000 done\n",
      "1040/10000 done\n",
      "1050/10000 done\n",
      "1060/10000 done\n",
      "1070/10000 done\n",
      "1080/10000 done\n",
      "1090/10000 done\n",
      "1100/10000 done\n",
      "1110/10000 done\n",
      "1120/10000 done\n",
      "1130/10000 done\n",
      "1140/10000 done\n",
      "1150/10000 done\n",
      "1160/10000 done\n",
      "1170/10000 done\n",
      "1180/10000 done\n",
      "1190/10000 done\n",
      "1200/10000 done\n",
      "1210/10000 done\n",
      "1220/10000 done\n",
      "1230/10000 done\n",
      "1240/10000 done\n",
      "1250/10000 done\n",
      "1260/10000 done\n",
      "1270/10000 done\n",
      "1280/10000 done\n",
      "1290/10000 done\n",
      "1300/10000 done\n",
      "1310/10000 done\n",
      "1320/10000 done\n",
      "1330/10000 done\n",
      "1340/10000 done\n",
      "1350/10000 done\n",
      "1360/10000 done\n",
      "1370/10000 done\n",
      "1380/10000 done\n",
      "1390/10000 done\n",
      "1400/10000 done\n",
      "1410/10000 done\n",
      "1420/10000 done\n",
      "1430/10000 done\n",
      "1440/10000 done\n",
      "1450/10000 done\n",
      "1460/10000 done\n",
      "1470/10000 done\n",
      "1480/10000 done\n",
      "1490/10000 done\n",
      "1500/10000 done\n",
      "1510/10000 done\n",
      "1520/10000 done\n",
      "1530/10000 done\n",
      "1540/10000 done\n",
      "1550/10000 done\n",
      "1560/10000 done\n",
      "1570/10000 done\n",
      "1580/10000 done\n",
      "1590/10000 done\n",
      "1600/10000 done\n",
      "1610/10000 done\n",
      "1620/10000 done\n",
      "1630/10000 done\n",
      "1640/10000 done\n",
      "1650/10000 done\n",
      "1660/10000 done\n",
      "1670/10000 done\n",
      "1680/10000 done\n",
      "1690/10000 done\n",
      "1700/10000 done\n",
      "1710/10000 done\n",
      "1720/10000 done\n",
      "1730/10000 done\n",
      "1740/10000 done\n",
      "1750/10000 done\n",
      "1760/10000 done\n",
      "1770/10000 done\n",
      "1780/10000 done\n",
      "1790/10000 done\n",
      "1800/10000 done\n",
      "1810/10000 done\n",
      "1820/10000 done\n",
      "1830/10000 done\n",
      "1840/10000 done\n",
      "1850/10000 done\n",
      "1860/10000 done\n",
      "1870/10000 done\n",
      "1880/10000 done\n",
      "1890/10000 done\n",
      "1900/10000 done\n",
      "1910/10000 done\n",
      "1920/10000 done\n",
      "1930/10000 done\n",
      "1940/10000 done\n",
      "1950/10000 done\n",
      "1960/10000 done\n",
      "1970/10000 done\n",
      "1980/10000 done\n",
      "1990/10000 done\n",
      "2000/10000 done\n",
      "2010/10000 done\n",
      "2020/10000 done\n",
      "2030/10000 done\n",
      "2040/10000 done\n",
      "2050/10000 done\n",
      "2060/10000 done\n",
      "2070/10000 done\n",
      "2080/10000 done\n",
      "2090/10000 done\n",
      "2100/10000 done\n",
      "2110/10000 done\n",
      "2120/10000 done\n",
      "2130/10000 done\n",
      "2140/10000 done\n",
      "2150/10000 done\n",
      "2160/10000 done\n",
      "2170/10000 done\n",
      "2180/10000 done\n",
      "2190/10000 done\n",
      "2200/10000 done\n",
      "2210/10000 done\n",
      "2220/10000 done\n",
      "2230/10000 done\n",
      "2240/10000 done\n",
      "2250/10000 done\n",
      "2260/10000 done\n",
      "2270/10000 done\n",
      "2280/10000 done\n",
      "2290/10000 done\n",
      "2300/10000 done\n",
      "2310/10000 done\n",
      "2320/10000 done\n",
      "2330/10000 done\n",
      "2340/10000 done\n",
      "2350/10000 done\n",
      "2360/10000 done\n",
      "2370/10000 done\n",
      "2380/10000 done\n",
      "2390/10000 done\n",
      "2400/10000 done\n",
      "2410/10000 done\n",
      "2420/10000 done\n",
      "2430/10000 done\n",
      "2440/10000 done\n",
      "2450/10000 done\n",
      "2460/10000 done\n",
      "2470/10000 done\n",
      "2480/10000 done\n",
      "2490/10000 done\n",
      "2500/10000 done\n",
      "2510/10000 done\n",
      "2520/10000 done\n",
      "2530/10000 done\n",
      "2540/10000 done\n",
      "2550/10000 done\n",
      "2560/10000 done\n",
      "2570/10000 done\n",
      "2580/10000 done\n",
      "2590/10000 done\n",
      "2600/10000 done\n",
      "2610/10000 done\n",
      "2620/10000 done\n",
      "2630/10000 done\n",
      "2640/10000 done\n",
      "2650/10000 done\n",
      "2660/10000 done\n",
      "2670/10000 done\n",
      "2680/10000 done\n",
      "2690/10000 done\n",
      "2700/10000 done\n",
      "2710/10000 done\n",
      "2720/10000 done\n",
      "2730/10000 done\n",
      "2740/10000 done\n",
      "2750/10000 done\n",
      "2760/10000 done\n",
      "2770/10000 done\n",
      "2780/10000 done\n",
      "2790/10000 done\n",
      "2800/10000 done\n",
      "2810/10000 done\n",
      "2820/10000 done\n",
      "2830/10000 done\n",
      "2840/10000 done\n",
      "2850/10000 done\n",
      "2860/10000 done\n",
      "2870/10000 done\n",
      "2880/10000 done\n",
      "2890/10000 done\n",
      "2900/10000 done\n",
      "2910/10000 done\n",
      "2920/10000 done\n",
      "2930/10000 done\n",
      "2940/10000 done\n",
      "2950/10000 done\n",
      "2960/10000 done\n",
      "2970/10000 done\n",
      "2980/10000 done\n",
      "2990/10000 done\n",
      "3000/10000 done\n",
      "3010/10000 done\n",
      "3020/10000 done\n",
      "3030/10000 done\n",
      "3040/10000 done\n",
      "3050/10000 done\n",
      "3060/10000 done\n",
      "3070/10000 done\n",
      "3080/10000 done\n",
      "3090/10000 done\n",
      "3100/10000 done\n",
      "3110/10000 done\n",
      "3120/10000 done\n",
      "3130/10000 done\n",
      "3140/10000 done\n",
      "3150/10000 done\n",
      "3160/10000 done\n",
      "3170/10000 done\n",
      "3180/10000 done\n",
      "3190/10000 done\n",
      "3200/10000 done\n",
      "3210/10000 done\n",
      "3220/10000 done\n",
      "3230/10000 done\n",
      "3240/10000 done\n",
      "3250/10000 done\n",
      "3260/10000 done\n",
      "3270/10000 done\n",
      "3280/10000 done\n",
      "3290/10000 done\n",
      "3300/10000 done\n",
      "3310/10000 done\n",
      "3320/10000 done\n",
      "3330/10000 done\n",
      "3340/10000 done\n",
      "3350/10000 done\n",
      "3360/10000 done\n",
      "3370/10000 done\n",
      "3380/10000 done\n",
      "3390/10000 done\n",
      "3400/10000 done\n",
      "3410/10000 done\n",
      "3420/10000 done\n",
      "3430/10000 done\n",
      "3440/10000 done\n",
      "3450/10000 done\n",
      "3460/10000 done\n",
      "3470/10000 done\n",
      "3480/10000 done\n",
      "3490/10000 done\n",
      "3500/10000 done\n",
      "3510/10000 done\n",
      "3520/10000 done\n",
      "3530/10000 done\n",
      "3540/10000 done\n",
      "3550/10000 done\n",
      "3560/10000 done\n",
      "3570/10000 done\n",
      "3580/10000 done\n",
      "3590/10000 done\n",
      "3600/10000 done\n",
      "3610/10000 done\n",
      "3620/10000 done\n",
      "3630/10000 done\n",
      "3640/10000 done\n",
      "3650/10000 done\n",
      "3660/10000 done\n",
      "3670/10000 done\n",
      "3680/10000 done\n",
      "3690/10000 done\n",
      "3700/10000 done\n",
      "3710/10000 done\n",
      "3720/10000 done\n",
      "3730/10000 done\n",
      "3740/10000 done\n",
      "3750/10000 done\n",
      "3760/10000 done\n",
      "3770/10000 done\n",
      "3780/10000 done\n",
      "3790/10000 done\n",
      "3800/10000 done\n",
      "3810/10000 done\n",
      "3820/10000 done\n",
      "3830/10000 done\n",
      "3840/10000 done\n",
      "3850/10000 done\n",
      "3860/10000 done\n",
      "3870/10000 done\n",
      "3880/10000 done\n",
      "3890/10000 done\n",
      "3900/10000 done\n",
      "3910/10000 done\n",
      "3920/10000 done\n",
      "3930/10000 done\n",
      "3940/10000 done\n",
      "3950/10000 done\n",
      "3960/10000 done\n",
      "3970/10000 done\n",
      "3980/10000 done\n",
      "3990/10000 done\n",
      "4000/10000 done\n",
      "4010/10000 done\n",
      "4020/10000 done\n",
      "4030/10000 done\n",
      "4040/10000 done\n",
      "4050/10000 done\n",
      "4060/10000 done\n",
      "4070/10000 done\n",
      "4080/10000 done\n",
      "4090/10000 done\n",
      "4100/10000 done\n",
      "4110/10000 done\n",
      "4120/10000 done\n",
      "4130/10000 done\n",
      "4140/10000 done\n",
      "4150/10000 done\n",
      "4160/10000 done\n",
      "4170/10000 done\n",
      "4180/10000 done\n",
      "4190/10000 done\n",
      "4200/10000 done\n",
      "4210/10000 done\n",
      "4220/10000 done\n",
      "4230/10000 done\n",
      "4240/10000 done\n",
      "4250/10000 done\n",
      "4260/10000 done\n",
      "4270/10000 done\n",
      "4280/10000 done\n",
      "4290/10000 done\n",
      "4300/10000 done\n",
      "4310/10000 done\n",
      "4320/10000 done\n",
      "4330/10000 done\n",
      "4340/10000 done\n",
      "4350/10000 done\n",
      "4360/10000 done\n",
      "4370/10000 done\n",
      "4380/10000 done\n",
      "4390/10000 done\n",
      "4400/10000 done\n",
      "4410/10000 done\n",
      "4420/10000 done\n",
      "4430/10000 done\n",
      "4440/10000 done\n",
      "4450/10000 done\n",
      "4460/10000 done\n",
      "4470/10000 done\n",
      "4480/10000 done\n",
      "4490/10000 done\n",
      "4500/10000 done\n",
      "4510/10000 done\n",
      "4520/10000 done\n",
      "4530/10000 done\n",
      "4540/10000 done\n",
      "4550/10000 done\n",
      "4560/10000 done\n",
      "4570/10000 done\n",
      "4580/10000 done\n",
      "4590/10000 done\n",
      "4600/10000 done\n",
      "4610/10000 done\n",
      "4620/10000 done\n",
      "4630/10000 done\n",
      "4640/10000 done\n",
      "4650/10000 done\n",
      "4660/10000 done\n",
      "4670/10000 done\n",
      "4680/10000 done\n",
      "4690/10000 done\n",
      "4700/10000 done\n",
      "4710/10000 done\n",
      "4720/10000 done\n",
      "4730/10000 done\n",
      "4740/10000 done\n",
      "4750/10000 done\n",
      "4760/10000 done\n",
      "4770/10000 done\n",
      "4780/10000 done\n",
      "4790/10000 done\n",
      "4800/10000 done\n",
      "4810/10000 done\n",
      "4820/10000 done\n",
      "4830/10000 done\n",
      "4840/10000 done\n",
      "4850/10000 done\n",
      "4860/10000 done\n",
      "4870/10000 done\n",
      "4880/10000 done\n",
      "4890/10000 done\n",
      "4900/10000 done\n",
      "4910/10000 done\n",
      "4920/10000 done\n",
      "4930/10000 done\n",
      "4940/10000 done\n",
      "4950/10000 done\n",
      "4960/10000 done\n",
      "4970/10000 done\n",
      "4980/10000 done\n",
      "4990/10000 done\n",
      "5000/10000 done\n",
      "5010/10000 done\n",
      "5020/10000 done\n",
      "5030/10000 done\n",
      "5040/10000 done\n",
      "5050/10000 done\n",
      "5060/10000 done\n",
      "5070/10000 done\n",
      "5080/10000 done\n",
      "5090/10000 done\n",
      "5100/10000 done\n",
      "5110/10000 done\n",
      "5120/10000 done\n",
      "5130/10000 done\n",
      "5140/10000 done\n",
      "5150/10000 done\n",
      "5160/10000 done\n",
      "5170/10000 done\n",
      "5180/10000 done\n",
      "5190/10000 done\n",
      "5200/10000 done\n",
      "5210/10000 done\n",
      "5220/10000 done\n",
      "5230/10000 done\n",
      "5240/10000 done\n",
      "5250/10000 done\n",
      "5260/10000 done\n",
      "5270/10000 done\n",
      "5280/10000 done\n",
      "5290/10000 done\n",
      "5300/10000 done\n",
      "5310/10000 done\n",
      "5320/10000 done\n",
      "5330/10000 done\n",
      "5340/10000 done\n",
      "5350/10000 done\n",
      "5360/10000 done\n",
      "5370/10000 done\n",
      "5380/10000 done\n",
      "5390/10000 done\n",
      "5400/10000 done\n",
      "5410/10000 done\n",
      "5420/10000 done\n",
      "5430/10000 done\n",
      "5440/10000 done\n",
      "5450/10000 done\n",
      "5460/10000 done\n",
      "5470/10000 done\n",
      "5480/10000 done\n",
      "5490/10000 done\n",
      "5500/10000 done\n",
      "5510/10000 done\n",
      "5520/10000 done\n",
      "5530/10000 done\n",
      "5540/10000 done\n",
      "5550/10000 done\n",
      "5560/10000 done\n",
      "5570/10000 done\n",
      "5580/10000 done\n",
      "5590/10000 done\n",
      "5600/10000 done\n",
      "5610/10000 done\n",
      "5620/10000 done\n",
      "5630/10000 done\n",
      "5640/10000 done\n",
      "5650/10000 done\n",
      "5660/10000 done\n",
      "5670/10000 done\n",
      "5680/10000 done\n",
      "5690/10000 done\n",
      "5700/10000 done\n",
      "5710/10000 done\n",
      "5720/10000 done\n",
      "5730/10000 done\n",
      "5740/10000 done\n",
      "5750/10000 done\n",
      "5760/10000 done\n",
      "5770/10000 done\n",
      "5780/10000 done\n",
      "5790/10000 done\n",
      "5800/10000 done\n",
      "5810/10000 done\n",
      "5820/10000 done\n",
      "5830/10000 done\n",
      "5840/10000 done\n",
      "5850/10000 done\n",
      "5860/10000 done\n",
      "5870/10000 done\n",
      "5880/10000 done\n",
      "5890/10000 done\n",
      "5900/10000 done\n",
      "5910/10000 done\n",
      "5920/10000 done\n",
      "5930/10000 done\n",
      "5940/10000 done\n",
      "5950/10000 done\n",
      "5960/10000 done\n",
      "5970/10000 done\n",
      "5980/10000 done\n",
      "5990/10000 done\n",
      "6000/10000 done\n",
      "6010/10000 done\n",
      "6020/10000 done\n",
      "6030/10000 done\n",
      "6040/10000 done\n",
      "6050/10000 done\n",
      "6060/10000 done\n",
      "6070/10000 done\n",
      "6080/10000 done\n",
      "6090/10000 done\n",
      "6100/10000 done\n",
      "6110/10000 done\n",
      "6120/10000 done\n",
      "6130/10000 done\n",
      "6140/10000 done\n",
      "6150/10000 done\n",
      "6160/10000 done\n",
      "6170/10000 done\n",
      "6180/10000 done\n",
      "6190/10000 done\n",
      "6200/10000 done\n",
      "6210/10000 done\n",
      "6220/10000 done\n",
      "6230/10000 done\n",
      "6240/10000 done\n",
      "6250/10000 done\n",
      "6260/10000 done\n",
      "6270/10000 done\n",
      "6280/10000 done\n",
      "6290/10000 done\n",
      "6300/10000 done\n",
      "6310/10000 done\n",
      "6320/10000 done\n",
      "6330/10000 done\n",
      "6340/10000 done\n",
      "6350/10000 done\n",
      "6360/10000 done\n",
      "6370/10000 done\n",
      "6380/10000 done\n",
      "6390/10000 done\n",
      "6400/10000 done\n",
      "6410/10000 done\n",
      "6420/10000 done\n",
      "6430/10000 done\n",
      "6440/10000 done\n",
      "6450/10000 done\n",
      "6460/10000 done\n",
      "6470/10000 done\n",
      "6480/10000 done\n",
      "6490/10000 done\n",
      "6500/10000 done\n",
      "6510/10000 done\n",
      "6520/10000 done\n",
      "6530/10000 done\n",
      "6540/10000 done\n",
      "6550/10000 done\n",
      "6560/10000 done\n",
      "6570/10000 done\n",
      "6580/10000 done\n",
      "6590/10000 done\n",
      "6600/10000 done\n",
      "6610/10000 done\n",
      "6620/10000 done\n",
      "6630/10000 done\n",
      "6640/10000 done\n",
      "6650/10000 done\n",
      "6660/10000 done\n",
      "6670/10000 done\n",
      "6680/10000 done\n",
      "6690/10000 done\n",
      "6700/10000 done\n",
      "6710/10000 done\n",
      "6720/10000 done\n",
      "6730/10000 done\n",
      "6740/10000 done\n",
      "6750/10000 done\n",
      "6760/10000 done\n",
      "6770/10000 done\n",
      "6780/10000 done\n",
      "6790/10000 done\n",
      "6800/10000 done\n",
      "6810/10000 done\n",
      "6820/10000 done\n",
      "6830/10000 done\n",
      "6840/10000 done\n",
      "6850/10000 done\n",
      "6860/10000 done\n",
      "6870/10000 done\n",
      "6880/10000 done\n",
      "6890/10000 done\n",
      "6900/10000 done\n",
      "6910/10000 done\n",
      "6920/10000 done\n",
      "6930/10000 done\n",
      "6940/10000 done\n",
      "6950/10000 done\n",
      "6960/10000 done\n",
      "6970/10000 done\n",
      "6980/10000 done\n",
      "6990/10000 done\n",
      "7000/10000 done\n",
      "7010/10000 done\n",
      "7020/10000 done\n",
      "7030/10000 done\n",
      "7040/10000 done\n",
      "7050/10000 done\n",
      "7060/10000 done\n",
      "7070/10000 done\n",
      "7080/10000 done\n",
      "7090/10000 done\n",
      "7100/10000 done\n",
      "7110/10000 done\n",
      "7120/10000 done\n",
      "7130/10000 done\n",
      "7140/10000 done\n",
      "7150/10000 done\n",
      "7160/10000 done\n",
      "7170/10000 done\n",
      "7180/10000 done\n",
      "7190/10000 done\n",
      "7200/10000 done\n",
      "7210/10000 done\n",
      "7220/10000 done\n",
      "7230/10000 done\n",
      "7240/10000 done\n",
      "7250/10000 done\n",
      "7260/10000 done\n",
      "7270/10000 done\n",
      "7280/10000 done\n",
      "7290/10000 done\n",
      "7300/10000 done\n",
      "7310/10000 done\n",
      "7320/10000 done\n",
      "7330/10000 done\n",
      "7340/10000 done\n",
      "7350/10000 done\n",
      "7360/10000 done\n",
      "7370/10000 done\n",
      "7380/10000 done\n",
      "7390/10000 done\n",
      "7400/10000 done\n",
      "7410/10000 done\n",
      "7420/10000 done\n",
      "7430/10000 done\n",
      "7440/10000 done\n",
      "7450/10000 done\n",
      "7460/10000 done\n",
      "7470/10000 done\n",
      "7480/10000 done\n",
      "7490/10000 done\n",
      "7500/10000 done\n",
      "7510/10000 done\n",
      "7520/10000 done\n",
      "7530/10000 done\n",
      "7540/10000 done\n",
      "7550/10000 done\n",
      "7560/10000 done\n",
      "7570/10000 done\n",
      "7580/10000 done\n",
      "7590/10000 done\n",
      "7600/10000 done\n",
      "7610/10000 done\n",
      "7620/10000 done\n",
      "7630/10000 done\n",
      "7640/10000 done\n",
      "7650/10000 done\n",
      "7660/10000 done\n",
      "7670/10000 done\n",
      "7680/10000 done\n",
      "7690/10000 done\n",
      "7700/10000 done\n",
      "7710/10000 done\n",
      "7720/10000 done\n",
      "7730/10000 done\n",
      "7740/10000 done\n",
      "7750/10000 done\n",
      "7760/10000 done\n",
      "7770/10000 done\n",
      "7780/10000 done\n",
      "7790/10000 done\n",
      "7800/10000 done\n",
      "7810/10000 done\n",
      "7820/10000 done\n",
      "7830/10000 done\n",
      "7840/10000 done\n",
      "7850/10000 done\n",
      "7860/10000 done\n",
      "7870/10000 done\n",
      "7880/10000 done\n",
      "7890/10000 done\n",
      "7900/10000 done\n",
      "7910/10000 done\n",
      "7920/10000 done\n",
      "7930/10000 done\n",
      "7940/10000 done\n",
      "7950/10000 done\n",
      "7960/10000 done\n",
      "7970/10000 done\n",
      "7980/10000 done\n",
      "7990/10000 done\n",
      "8000/10000 done\n",
      "8010/10000 done\n",
      "8020/10000 done\n",
      "8030/10000 done\n",
      "8040/10000 done\n",
      "8050/10000 done\n",
      "8060/10000 done\n",
      "8070/10000 done\n",
      "8080/10000 done\n",
      "8090/10000 done\n",
      "8100/10000 done\n",
      "8110/10000 done\n",
      "8120/10000 done\n",
      "8130/10000 done\n",
      "8140/10000 done\n",
      "8150/10000 done\n",
      "8160/10000 done\n",
      "8170/10000 done\n",
      "8180/10000 done\n",
      "8190/10000 done\n",
      "8200/10000 done\n",
      "8210/10000 done\n",
      "8220/10000 done\n",
      "8230/10000 done\n",
      "8240/10000 done\n",
      "8250/10000 done\n",
      "8260/10000 done\n",
      "8270/10000 done\n",
      "8280/10000 done\n",
      "8290/10000 done\n",
      "8300/10000 done\n",
      "8310/10000 done\n",
      "8320/10000 done\n",
      "8330/10000 done\n",
      "8340/10000 done\n",
      "8350/10000 done\n",
      "8360/10000 done\n",
      "8370/10000 done\n",
      "8380/10000 done\n",
      "8390/10000 done\n",
      "8400/10000 done\n",
      "8410/10000 done\n",
      "8420/10000 done\n",
      "8430/10000 done\n",
      "8440/10000 done\n",
      "8450/10000 done\n",
      "8460/10000 done\n",
      "8470/10000 done\n",
      "8480/10000 done\n",
      "8490/10000 done\n",
      "8500/10000 done\n",
      "8510/10000 done\n",
      "8520/10000 done\n",
      "8530/10000 done\n",
      "8540/10000 done\n",
      "8550/10000 done\n",
      "8560/10000 done\n",
      "8570/10000 done\n",
      "8580/10000 done\n",
      "8590/10000 done\n",
      "8600/10000 done\n",
      "8610/10000 done\n",
      "8620/10000 done\n",
      "8630/10000 done\n",
      "8640/10000 done\n",
      "8650/10000 done\n",
      "8660/10000 done\n",
      "8670/10000 done\n",
      "8680/10000 done\n",
      "8690/10000 done\n",
      "8700/10000 done\n",
      "8710/10000 done\n",
      "8720/10000 done\n",
      "8730/10000 done\n",
      "8740/10000 done\n",
      "8750/10000 done\n",
      "8760/10000 done\n",
      "8770/10000 done\n",
      "8780/10000 done\n",
      "8790/10000 done\n",
      "8800/10000 done\n",
      "8810/10000 done\n",
      "8820/10000 done\n",
      "8830/10000 done\n",
      "8840/10000 done\n",
      "8850/10000 done\n",
      "8860/10000 done\n",
      "8870/10000 done\n",
      "8880/10000 done\n",
      "8890/10000 done\n",
      "8900/10000 done\n",
      "8910/10000 done\n",
      "8920/10000 done\n",
      "8930/10000 done\n",
      "8940/10000 done\n",
      "8950/10000 done\n",
      "8960/10000 done\n",
      "8970/10000 done\n",
      "8980/10000 done\n",
      "8990/10000 done\n",
      "9000/10000 done\n",
      "9010/10000 done\n",
      "9020/10000 done\n",
      "9030/10000 done\n",
      "9040/10000 done\n",
      "9050/10000 done\n",
      "9060/10000 done\n",
      "9070/10000 done\n",
      "9080/10000 done\n",
      "9090/10000 done\n",
      "9100/10000 done\n",
      "9110/10000 done\n",
      "9120/10000 done\n",
      "9130/10000 done\n",
      "9140/10000 done\n",
      "9150/10000 done\n",
      "9160/10000 done\n",
      "9170/10000 done\n",
      "9180/10000 done\n",
      "9190/10000 done\n",
      "9200/10000 done\n",
      "9210/10000 done\n",
      "9220/10000 done\n",
      "9230/10000 done\n",
      "9240/10000 done\n",
      "9250/10000 done\n",
      "9260/10000 done\n",
      "9270/10000 done\n",
      "9280/10000 done\n",
      "9290/10000 done\n",
      "9300/10000 done\n",
      "9310/10000 done\n",
      "9320/10000 done\n",
      "9330/10000 done\n",
      "9340/10000 done\n",
      "9350/10000 done\n",
      "9360/10000 done\n",
      "9370/10000 done\n",
      "9380/10000 done\n",
      "9390/10000 done\n",
      "9400/10000 done\n",
      "9410/10000 done\n",
      "9420/10000 done\n",
      "9430/10000 done\n",
      "9440/10000 done\n",
      "9450/10000 done\n",
      "9460/10000 done\n",
      "9470/10000 done\n",
      "9480/10000 done\n",
      "9490/10000 done\n",
      "9500/10000 done\n",
      "9510/10000 done\n",
      "9520/10000 done\n",
      "9530/10000 done\n",
      "9540/10000 done\n",
      "9550/10000 done\n",
      "9560/10000 done\n",
      "9570/10000 done\n",
      "9580/10000 done\n",
      "9590/10000 done\n",
      "9600/10000 done\n",
      "9610/10000 done\n",
      "9620/10000 done\n",
      "9630/10000 done\n",
      "9640/10000 done\n",
      "9650/10000 done\n",
      "9660/10000 done\n",
      "9670/10000 done\n",
      "9680/10000 done\n",
      "9690/10000 done\n",
      "9700/10000 done\n",
      "9710/10000 done\n",
      "9720/10000 done\n",
      "9730/10000 done\n",
      "9740/10000 done\n",
      "9750/10000 done\n",
      "9760/10000 done\n",
      "9770/10000 done\n",
      "9780/10000 done\n",
      "9790/10000 done\n",
      "9800/10000 done\n",
      "9810/10000 done\n",
      "9820/10000 done\n",
      "9830/10000 done\n",
      "9840/10000 done\n",
      "9850/10000 done\n",
      "9860/10000 done\n",
      "9870/10000 done\n",
      "9880/10000 done\n",
      "9890/10000 done\n",
      "9900/10000 done\n",
      "9910/10000 done\n",
      "9920/10000 done\n",
      "9930/10000 done\n",
      "9940/10000 done\n",
      "9950/10000 done\n",
      "9960/10000 done\n",
      "9970/10000 done\n",
      "9980/10000 done\n",
      "9990/10000 done\n",
      "10000/10000 done\n"
     ]
    }
   ],
   "source": [
    "def projection(matrix):\n",
    "    return np.real(np.matrix([[matrix[0,0],0,0,matrix[0,3]/2+matrix[3,0]/2],\\\n",
    "                                [0,matrix[2,2]/2+matrix[1,1]/2,0,0],\\\n",
    "                                [0,0,matrix[2,2]/2+matrix[1,1]/2,0],\\\n",
    "                                [matrix[0,3]/2+matrix[3,0]/2,0,0,matrix[3,3]]]))\n",
    "samples = []\n",
    "for i in range(10000):\n",
    "    initial_matrix = rand_PSDM(4)\n",
    "    projected = projection(initial_matrix)\n",
    "    parameters = [projected[0,0], projected[0,3], projected[1,1], projected[3,3]]\n",
    "    projected = density_matrix(projected)\n",
    "    projected.set(20000)\n",
    "    samples.append((projected.data, parameters))\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'{i+1}/10000 done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bins(data):\n",
    "    counts=np.zeros(100)\n",
    "    for dat in data:\n",
    "        try:\n",
    "            counts[int(dat*100)]+=1/len(data)\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_new = []\n",
    "for hist, par in samples_load:\n",
    "    samples_new.append((data_to_bins(hist), par))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_proj_samps.dat', 'wb') as file:\n",
    "    pickle.dump(samples_new, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_proj_samps.dat', 'rb') as file:\n",
    "    samples_load = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = samples_new[:8000]\n",
    "samples_val = samples_new[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24111, 0.20476, 0.2126 , ..., 0.24117, 0.20626, 0.24237])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist, params = samples_load[0]\n",
    "hist.astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class proj_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,samples):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.samples = samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hist, params = self.samples[idx]\n",
    "        hist = torch.from_numpy(hist).float()\n",
    "        params = torch.Tensor(params).float()\n",
    "        return hist, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(100, 50)\n",
    "        self.output_layer = nn.Linear(20, 4)\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(50, 100),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(100,25),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(25,25),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(25,20),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainig & validation loop\n",
    "def fit(model, samples_train, samples_val, batch_size=10, lr=0.05):    \n",
    "    from torchmetrics import MeanSquaredError\n",
    "    data_loader_train = DataLoader(proj_dataset(samples_train), shuffle=True, batch_size=batch_size)\n",
    "    data_loader_val = DataLoader(proj_dataset(samples_val), shuffle=True, batch_size=batch_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr) \n",
    "    metrics = MeanSquaredError()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        #Training\n",
    "        model.train()\n",
    "        for hist, params in data_loader_train:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(hist)\n",
    "            loss = criterion(pred, params)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            metrics(pred, params)\n",
    "        train_loss = metrics.compute()\n",
    "        metrics.reset()\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for hist, params in data_loader_val:\n",
    "                pred = model(hist)\n",
    "                metrics(pred, params)\n",
    "        val_loss = metrics.compute()\n",
    "        metrics.reset()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/10: training loss {train_loss}, validation loss {val_loss}')\n",
    "    \n",
    "    return model    \n",
    "    \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def evaluate_model(model, samples_eval, batch_size=10):\n",
    "    import torchmetrics\n",
    "    metrics = torchmetrics.MeanSquaredError()\n",
    "    data_loader = DataLoader(proj_dataset(samples_eval), shuffle=True, batch_size=batch_size)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for hist, params in data_loader:\n",
    "            pred = model(hist)\n",
    "            metrics(pred, params)\n",
    "    return metrics.compute()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: training loss 0.031431976705789566, validation loss 0.009541042149066925\n",
      "Epoch 2/10: training loss 0.009355119429528713, validation loss 0.008624564856290817\n",
      "Epoch 3/10: training loss 0.00927263218909502, validation loss 0.01006998959928751\n",
      "Epoch 4/10: training loss 0.009325104765594006, validation loss 0.008918026462197304\n",
      "Epoch 5/10: training loss 0.009328906424343586, validation loss 0.008558460511267185\n",
      "Epoch 6/10: training loss 0.009346254169940948, validation loss 0.009577351622283459\n",
      "Epoch 7/10: training loss 0.00935167446732521, validation loss 0.008997203782200813\n",
      "Epoch 8/10: training loss 0.00934012420475483, validation loss 0.009078686125576496\n",
      "Epoch 9/10: training loss 0.009336731396615505, validation loss 0.009032435715198517\n",
      "Epoch 10/10: training loss 0.00928193423897028, validation loss 0.008775408379733562\n"
     ]
    }
   ],
   "source": [
    "model = fit(Net(), samples_train, samples_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'proj_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2827, -0.0024,  0.2314,  0.2634], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.from_numpy(samples_new[10][0]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30940762059894866,\n",
       " -0.005726067205798068,\n",
       " 0.27777555818594596,\n",
       " 0.13504126302915936]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_new[10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = Net()\n",
    "model_loaded.load_state_dict(torch.load('proj_model.model'))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Werner states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angle</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>[0.0, 0.01]</th>\n",
       "      <th>[0.01, 0.02]</th>\n",
       "      <th>[0.02, 0.03]</th>\n",
       "      <th>[0.03, 0.04]</th>\n",
       "      <th>[0.04, 0.05]</th>\n",
       "      <th>[0.05, 0.06]</th>\n",
       "      <th>[0.06, 0.07]</th>\n",
       "      <th>[0.07, 0.08]</th>\n",
       "      <th>...</th>\n",
       "      <th>[0.9, 0.91]</th>\n",
       "      <th>[0.91, 0.92]</th>\n",
       "      <th>[0.92, 0.93]</th>\n",
       "      <th>[0.93, 0.94]</th>\n",
       "      <th>[0.94, 0.95]</th>\n",
       "      <th>[0.95, 0.96]</th>\n",
       "      <th>[0.96, 0.97]</th>\n",
       "      <th>[0.97, 0.98]</th>\n",
       "      <th>[0.98, 0.99]</th>\n",
       "      <th>[0.99, 1.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333026</td>\n",
       "      <td>0.045424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568860</td>\n",
       "      <td>0.448408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.620751</td>\n",
       "      <td>0.267946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.635826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401182</td>\n",
       "      <td>0.933977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00898</td>\n",
       "      <td>0.02606</td>\n",
       "      <td>0.02698</td>\n",
       "      <td>0.02618</td>\n",
       "      <td>0.02702</td>\n",
       "      <td>0.02636</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Angle  Visibility  [0.0, 0.01]  [0.01, 0.02]  [0.02, 0.03]  \\\n",
       "0  0.333026    0.045424          0.0       0.00000       0.00000   \n",
       "1  0.568860    0.448408          0.0       0.00000       0.00000   \n",
       "2  0.620751    0.267946          0.0       0.00000       0.00000   \n",
       "3  0.127500    0.635826          0.0       0.00000       0.00000   \n",
       "4  0.401182    0.933977          0.0       0.00898       0.02606   \n",
       "\n",
       "   [0.03, 0.04]  [0.04, 0.05]  [0.05, 0.06]  [0.06, 0.07]  [0.07, 0.08]  ...  \\\n",
       "0       0.00000       0.00000       0.00000       0.00000        0.0000  ...   \n",
       "1       0.00000       0.00000       0.00000       0.00000        0.0000  ...   \n",
       "2       0.00000       0.00000       0.00000       0.00000        0.0000  ...   \n",
       "3       0.00000       0.00000       0.00000       0.00000        0.0000  ...   \n",
       "4       0.02698       0.02618       0.02702       0.02636        0.0261  ...   \n",
       "\n",
       "   [0.9, 0.91]  [0.91, 0.92]  [0.92, 0.93]  [0.93, 0.94]  [0.94, 0.95]  \\\n",
       "0          0.0           0.0           0.0           0.0           0.0   \n",
       "1          0.0           0.0           0.0           0.0           0.0   \n",
       "2          0.0           0.0           0.0           0.0           0.0   \n",
       "3          0.0           0.0           0.0           0.0           0.0   \n",
       "4          0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   [0.95, 0.96]  [0.96, 0.97]  [0.97, 0.98]  [0.98, 0.99]  [0.99, 1.0]  \n",
       "0           0.0           0.0           0.0           0.0          0.0  \n",
       "1           0.0           0.0           0.0           0.0          0.0  \n",
       "2           0.0           0.0           0.0           0.0          0.0  \n",
       "3           0.0           0.0           0.0           0.0          0.0  \n",
       "4           0.0           0.0           0.0           0.0          0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('werner_sample.csv', index_col='Unnamed: 0')\n",
    "df_test = pd.read_csv('werner_test.csv', index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class werner_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,samples):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hist, params = self.samples[idx]\n",
    "        hist = torch.from_numpy(hist).float()\n",
    "        params = torch.Tensor(params).float()\n",
    "        return hist, params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
